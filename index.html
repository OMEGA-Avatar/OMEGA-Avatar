<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="We propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="Single-view Feed-forward Generation, Generalizable Full-head Avatars, Animation-ready, Gaussian Splatting">
  <!-- TODO: List all authors -->
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="We propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://omega-avatar.github.io/OMEGA-Avatar/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://omega-avatar.github.io/OMEGA-Avatar/static/images/teaserv2.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars - Research Preview">
  <meta property="article:published_time" content="2026-02-10T18:00:00.000Z">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Single-view Feed-forward Generation">
  <meta property="article:tag" content="Generalizable Full-head Avatars">
    <meta property="article:tag" content="Animation-ready">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
<!--  &lt;!&ndash; TODO: Replace with your lab/institution Twitter handle &ndash;&gt;-->
<!--  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">-->
<!--  &lt;!&ndash; TODO: Replace with first author's Twitter handle &ndash;&gt;-->
<!--  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">-->
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="We propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://omega-avatar.github.io/OMEGA-Avatar/static/images/teaserv2.png">
  <meta name="twitter:image:alt" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatarsw">
  <meta name="citation_publication_date" content="2026">
<!--  <meta name="citation_conference_title" content="CONFERENCE_NAME">-->
<!--  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">-->

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="">
  <link rel="apple-touch-icon" href="">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars",
    "description": "We propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.",
    "datePublished": "2026-02-11",
    "publisher": {
      "@type": "Organization",
      "name": "arxiv"
    },
    "url": "https://omega-avatar.github.io/OMEGA-Avatar",
    "image": "https://omega-avatar.github.io/OMEGA-Avatar/static/images/teaserv2.png",
    "keywords": ["Single-view Feed-forward Generation", "Generalizable Full-head Avatars", "Animation-ready"],
    "abstract": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously.To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://omega-avatar.github.io/OMEGA-Avatar"
    }
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "url": "https://omega-avatar.github.io/OMEGA-Avatar"
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars</h1>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2602.11693"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
<!--                  <span class="link-block">-->
<!--                    <a href="https://youtu.be/Lhf6aVFdaTk"-->
<!--                       class="external-link button is-normal is-rounded is-dark">-->
<!--                      <span class="icon">-->
<!--                          <i class="fab fa-youtube"></i>-->
<!--                      </span>-->
<!--                      <span>Video</span>-->
<!--                    </a>-->
<!--                  </span>-->
    <!--               Code Link. -->
                  <span class="link-block">
                    <a href=""
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-github"></i>
                      </span>
                      <span>Code(coming soon)</span>
                      </a>
                  </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaserv2.png" alt="OMEGA-Avatar Teaser" style="width:85%;margin: 0 auto;display: block;">

      <div class="content has-text-left is-size-6 mt-4">
        Given a single portrait image across diverse styles (left), our method generates a high-fidelity Full-Head Gaussian avatar via a feed-forward network (middle). The reconstructed avatars include the back of the head and are capable of high-quality animations (right).
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      &lt;!&ndash; TODO: Replace with your teaser video &ndash;&gt;-->
<!--      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">-->
<!--        &lt;!&ndash; TODO: Add your video file path here &ndash;&gt;-->
<!--        <source src="static/videos/banner_video.mp4" type="video/mp4">-->
<!--      </video>-->
<!--      &lt;!&ndash; TODO: Replace with your video description &ndash;&gt;-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. -->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge.
            We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously.
            To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image.
            Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components.
            First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure.
            Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion.
            This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization.
            Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!--&lt;!&ndash; Image carousel &ndash;&gt;-->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--       <div class="item">-->
<!--        &lt;!&ndash; TODO: Replace with your research result images &ndash;&gt;-->
<!--        <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>-->
<!--        &lt;!&ndash; TODO: Replace with description of this result &ndash;&gt;-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--          First image description.-->
<!--        </h2>-->
<!--      </div>-->
<!--      <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--          Second image description.-->
<!--        </h2>-->
<!--      </div>-->
<!--      <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--         Third image description.-->
<!--       </h2>-->
<!--     </div>-->
<!--     <div class="item">-->
<!--      &lt;!&ndash; Your image here &ndash;&gt;-->
<!--      <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Fourth image description.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</div>-->
<!--</div>-->
<!--</section>-->
<!-- End image carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container" style="max-width: 900px;">
      <h2 class="title is-4 has-text-centered" style="margin-bottom: 0px;">Expression Reenactment</h2>
      <div id="results-carousel-1" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/macron.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/Lieu-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/May.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container" style="max-width: 960px;">
      <h2 class="title is-4 has-text-centered" style="margin-bottom: 0px;">Animatable Full-Head Reconstruction</h2>
      <div id="results-carousel-2" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video4" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/shaheen-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video5" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/obama-1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <!-- 统一的大容器，宽度限制为 900px -->
    <div class="container" style="max-width: 1020px;">

      <!-- 统一的标题 -->
      <h2 class="title is-4 has-text-centered" style="margin-bottom: 0px;">Comparison</h2>

      <!-- 第一个轮播 (Taylor Swift) -->
      <div id="results-carousel-3" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video6" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Taylor1-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video7" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Taylor2-1.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <!-- 第二个轮播 (Biden/Trump) -->
      <!-- 注意：这里加了 style="margin-top: 20px;" 来控制两排视频的间距 -->
      <div id="results-carousel-4" class="carousel results-carousel" style="margin-top: 0px;">
        <div class="item item-video1">
          <video poster="" id="video8" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Biden1-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video9" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Biden2-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video10" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Trump1-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video11" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/Trump2-1.mp4" type="video/mp4">
          </video>
        </div>
      </div>

    </div>
  </div>
</section>

<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container" style="max-width: 900px;">-->
<!--      <h2 class="title is-4">Comparison</h2>-->
<!--      <div id="results-carousel-3" class="carousel results-carousel">-->
<!--        <div class="item item-video1">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video6" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Taylor1-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video2">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video7" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Taylor2-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container" style="max-width: 900px;">-->
<!--      <h2 class="title is-4">Comparison</h2>-->
<!--      <div id="results-carousel-4" class="carousel results-carousel">-->
<!--        <div class="item item-video1">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video8" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Biden1-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video2">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video9" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Biden2-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video3">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video10" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Trump1-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video4">-->
<!--          &lt;!&ndash; TODO: Add poster image for better preview &ndash;&gt;-->
<!--          <video poster="" id="video11" controls muted loop height="100%" preload="metadata">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/Trump2-1.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->

<!-- End video carousel-->


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Methodology</h2>

        <div class="publication-image">
          <img src="static/images/pipelinev2.png" alt="OMEGA-Avatar Pipeline Architecture" style="width:85%; margin: 0 auto;">
        </div>

        <div class="content has-text-justified mt-5">
          <p>
            <strong>Pipeline Overview:</strong> Given the source and target images, we leverage diffusion models to synthesize multi-view RGB images and corresponding normal maps. These normal maps are used to semantic-aware mesh deformation, while pixel-wise features are extracted from multi-view RGB images. Multi-view features are subsequently aggregated into a canonical UV feature map through the multi-view feature splatting module. The UV features and vertex features extracted from the deformed mesh are decoded and anchored to the mesh via UV mapping. For animation, the expression and pose derived from the target image are injected into the deformed mesh. Finally, the rendered output is enhanced by a neural refiner to generate the final full-head avatar.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-4 has-text-centered">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">

          <div class="publication-video">
            <!-- TODO: Replace with your YouTube video ID -->
            <iframe src="https://www.youtube.com/embed/Lhf6aVFdaTk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!--&lt;!&ndash; Paper poster &ndash;&gt;-->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      &lt;!&ndash; TODO: Replace with your poster PDF &ndash;&gt;-->
<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--&lt;!&ndash;End paper poster &ndash;&gt;-->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{OMEGA-Avatar2026,
  title={OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars},
  journal={Conference/Journal Name},
  year={2026},
  url={https://omega-avatar.github.io/OMEGA-Avatar}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </main>
  </body>
  </html>
